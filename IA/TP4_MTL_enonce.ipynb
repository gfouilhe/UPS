{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification multi-tâches\n",
    "\n",
    "On va expérimenter un problème de classification multi-tâches sur un jeu de données d'images, issu du travail suivant: \n",
    "\n",
    "3D Object Representations for Fine-Grained Categorization\n",
    "       Jonathan Krause, Michael Stark, Jia Deng, Li Fei-Fei\n",
    "       4th IEEE Workshop on 3D Representation and Recognition, at ICCV 2013 (3dRR-13). Sydney, Australia. Dec. 8, 2013.\n",
    "       \n",
    "Dans ce corpus, on a des images de voiture de différents modèles, de différentes marques et de différentes époques. \n",
    "\n",
    "On va essayer de prédire chacune de ses caractéristiques à partir de l'image. \n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut d'abord récupérer et désarchiver les fichiers suivants: \n",
    "    \n",
    "   http://ai.stanford.edu/~jkrause/car196/car_ims.tgz\n",
    "   \n",
    "   http://ai.stanford.edu/~jkrause/car196/cars_annos.mat\n",
    "   \n",
    "   Si vous avez une connexion trop lente en salle, vous pouvez utiliser cet échantillon plus petit: \n",
    "   \n",
    "   https://www.irit.fr/~Philippe.Muller/sample_cars.zip (10% du jeu de test complet)\n",
    "   \n",
    "Et mettez les dans un répertoire (par exemple Car_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'unzip' n'est pas reconnu en tant que commande interne\n",
      "ou externe, un programme ex�cutable ou un fichier de commandes.\n"
     ]
    }
   ],
   "source": [
    "!unzip http://ai.stanford.edu/~jkrause/car196/car_ims.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAR_PATH = \"./Car_dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muller/anaconda3/envs/visual/lib/python3.8/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: /media/muller/disque 2/anaconda3/envs/visual/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZNK3c1010TensorImpl36is_contiguous_nondefault_policy_implENS_12MemoryFormatE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "import torchvision.models as models\n",
    "from torchvision.transforms import ToTensor\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "from PIL import ImageFile\n",
    "from PIL import Image\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cars import load_annotations, brand_dict, vehicle_types_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour l'entrainement en torch, on a besoin d'un générateur d'instances, \n",
    "# qui sera utilisé par le générateur de batch\n",
    "class CarDataset(Dataset):\n",
    "    def __init__(self,car_path,transform,translation_dict):\n",
    "        self.path = car_path\n",
    "        self.folder = [x for x in os.listdir(car_path)]\n",
    "        self.transform = transform\n",
    "        self.translation_dict = translation_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.folder)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        img_loc = os.path.join(self.path, self.folder[idx])\n",
    "        image = Image.open(img_loc).convert('RGB')\n",
    "        single_img = self.transform(image)\n",
    "\n",
    "        label1 = translation_dict[self.folder[idx]][0]\n",
    "        label2 = translation_dict[self.folder[idx]][1]\n",
    "        label3 = translation_dict[self.folder[idx]][2]\n",
    "\n",
    "        sample = {'image':single_img, 'labels': {'label_brand':label1, \n",
    "                                                 'label_vehicle_type':label2, \n",
    "                                                 'label_epoch':label3}}\n",
    "        return sample   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_dict = load_annotations(CAR_PATH+\"/cars_annos.mat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A faire\n",
    "\n",
    "   - visualiez la distribution des classes de chaque tâche\n",
    "   - est-ce qu'elles sont équilibrées ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "    ])\n",
    "\n",
    "cardata = CarDataset(CAR_PATH+\"/car_ims\", transform=data_transforms,translation_dict=translation_dict)\n",
    "\n",
    "# on garde seulement 20% du dataset pour le train, car il est gros\n",
    "# pas la peine si vous avez pris l'échantillon faites 80%/20%/0\n",
    "train_len = int(cardata.__len__()*0.2)\n",
    "test_len  = int(cardata.__len__()*0.2)\n",
    "ignored   = int(cardata.__len__()*0.6)\n",
    "train_set, val_set, ignored_data = torch.utils.data.random_split(cardata, [train_len, test_len,ignored])\n",
    "\n",
    "# DataLoader va générer les batchs\n",
    "train_loader = DataLoader(train_set, batch_size=16, shuffle=True, \n",
    "                                num_workers=4, drop_last=True)\n",
    "test_loader = DataLoader(val_set, batch_size=16, shuffle=False, \n",
    "                               num_workers=4, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "print(cardata[0]['image'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A faire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A COMPLETER : il faut un modèle spécialisant chaque tâche\n",
    "# essayez par exemple avec une couche linéaire simple\n",
    "# ou une couche linéaire après une couche de drop-out\n",
    "class MultilabelClassifier(nn.Module):\n",
    "    def __init__(self, n_brand, n_vehicle_type, n_epoch):\n",
    "        super().__init__()\n",
    "        # la partie commune du modèle = resnet moins sa couche finale, dimension de sortie = 512\n",
    "        self.resnet = models.resnet34(pretrained=True)\n",
    "        self.model_wo_fc = nn.Sequential(*(list(self.resnet.children())[:-1]))\n",
    "\n",
    "        self.brand = ...\n",
    "        \n",
    "        self.vehicle_type = ...\n",
    "            \n",
    "        self_epoch = ...\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model_wo_fc(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        \n",
    "        return {\n",
    "            'brand': 0,\n",
    "            'vehicle_type': 0,\n",
    "            'epoch': 0\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MultilabelClassifier(6,5,2).to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On définit ici la fonction de loss globale\n",
    "# A FAIRE: quel autre choix pourrait-on faire ? \n",
    "#  si vous avez le temps essayez de changer cette loss globale\n",
    "def criterion(loss_func,outputs,pictures):\n",
    "    losses = 0\n",
    "    for i, key in enumerate(outputs):\n",
    "        losses += loss_func(outputs[key], pictures['labels'][f'label_{key}'].to(device))\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model,device,lr_rate,epochs,train_loader):\n",
    "    num_epochs = epochs\n",
    "    losses = []\n",
    "    checkpoint_losses = []\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr_rate)\n",
    "    n_total_steps = len(train_loader)\n",
    "\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        i = 0\n",
    "        for pictures in tqdm(train_loader,desc=f\"Epoque {epoch+1}\"):\n",
    "            images = pictures['image'].to(device)\n",
    "            pictures = pictures\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            loss = criterion(loss_func,outputs, pictures)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i+1) % (int(n_total_steps/1)) == 0:\n",
    "                checkpoint_loss = torch.tensor(losses).mean().item()\n",
    "                checkpoint_losses.append(checkpoint_loss)\n",
    "                print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {checkpoint_loss:.4f}')\n",
    "            i = i + 1\n",
    "    return checkpoint_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## A FAIRE  entrainez le modèle\n",
    "\n",
    "# checkpoint_losses ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de calcul des performances en validation\n",
    "# Que veut dire l'accuracy par classe ici ? corriger l'affichage\n",
    "def validation(model, dataloader, *args):\n",
    "    all_predictions = torch.tensor([]).to(device)\n",
    "    all_true_labels = torch.tensor([]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "            n_correct = []\n",
    "            n_class_correct = []\n",
    "            n_class_samples = []\n",
    "            n_samples = 0\n",
    "\n",
    "            for arg in args:\n",
    "                n_correct.append(len(arg))\n",
    "                n_class_correct.append([0 for i in range(len(arg))])\n",
    "                n_class_samples.append([0 for i in range(len(arg))])\n",
    "\n",
    "            # l'eval se fait par batch aussi, et sur le gpu si possible\n",
    "            for pictures in tqdm(dataloader):\n",
    "                images = pictures['image'].to(device)\n",
    "                outputs = model(images)\n",
    "                labels = [pictures['labels'][picture].to(device) for picture in pictures['labels']]\n",
    "\n",
    "                for i,out in enumerate(outputs):\n",
    "                    # quelle est la forme de outputs[out] ?\n",
    "                    _, predicted = torch.max(outputs[out],axis=1)\n",
    "                    n_correct[i] += (predicted == labels[i]).sum().item()\n",
    "\n",
    "                    if i == 0:\n",
    "                          n_samples += labels[i].size(0)\n",
    "\n",
    "                    for k in range(16):\n",
    "                        label = labels[i][k]\n",
    "                        pred = predicted[k]\n",
    "                        if (label == pred):\n",
    "                            n_class_correct[i][label] += 1\n",
    "                        n_class_samples[i][label] += 1\n",
    "\n",
    "    return n_correct,n_samples,n_class_correct,n_class_samples\n",
    "\n",
    "def class_acc(n_correct,n_samples,n_class_correct,n_class_samples,class_list):\n",
    "    for i in range(len(class_list)):\n",
    "          print(\"-------------------------------------------------\")\n",
    "          acc = 100.0 * n_correct[i] / n_samples\n",
    "          print(f'Overall class performance: {round(acc,1)} %')\n",
    "          for k in range(len(class_list[i])):\n",
    "              acc = 100.0 * n_class_correct[i][k] / n_class_samples[i][k]\n",
    "              print(f'Accuracy of {class_list[i][k]}: {round(acc,1)} %')\n",
    "    print(\"-------------------------------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_brand = list(brand_dict.values())\n",
    "classes_vehicle_type = list(vehicle_types_dict.values())\n",
    "classes_epoch = ['2009 and earlier','2010 and later']\n",
    "class_list = [classes_brand,classes_vehicle_type,classes_epoch]\n",
    "\n",
    "n_correct,n_samples,n_class_correct,n_class_samples = validation(model,test_loader,\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_acc(n_correct,n_samples,n_class_correct,n_class_samples,class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## A FAIRE : calculez les précision/rappel pour chaque classe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "d776b604cc3904292aea37f4daa2a46de34e87e5ec4d2ed68e9e515ab9feb7f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
